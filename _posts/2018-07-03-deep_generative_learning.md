---
layout: post
title: "深度生成学习" 
---

# 1、生成模型的基本概念

生成模型是使用无监督学习来生成与数据真实分布尽可能接近的新数据样本的模型。

对于简单数据分布的情况，我们可以假设数据满足某种概率分布，如高斯分布，这样数据分布的形式就已基本确定，接下来就是求解分布模型中的参数（当作一个参数学习问题来处理）。我们可以用$P(X)$的形式对数据建模，其中$X$代表数据。对于高斯分布，我们只需求解其均值和方差，就可以得到数据描述的形式。

对于稍复杂一些的情况，数据可能会被分成好几个部分，我们可以分别对每个部分用某种概率分布来表示（当作一个聚类问题来处理）。但由于这些数据来自于一个整体，我们在描述的时候一定要明确地指出数据是属于哪一个部分。像这样的描述虽然不会出现在数据的表示中，但对数据的产生却会产生十分重要的作用，这种变量一般被称作隐含变量。我们可以用$$P(X\mid Z)$$的形式对数据建模，其中$X$代表数据，$Z$代表隐含变量（也就是“数据属于哪一个部分”）。当然，还需要对$P(Z)$进行建模（这样才能得到联合概率分布$P(X,Z)$），不过$P(Z)$往往可以从已知数据集中各部分数据的比例估计得到。

实际上，上述问题还是比较简单的，大部分情况数据维数非常大，求解模型的具体形式非常困难，我们可以考虑从已知分布中采样得到一个随机数作为输入，新样本作为输出来进行相应建模，而并不需要显示地学得数据的分布情况。在这样的处理中一般用深度神经网络来进行建模，因此又叫深度生成模型，学习的过程叫作深度生成学习。

# 2、DBN

DBN是比较早的深度生成模型，叠加了多层的RBM，它通过逐层的预训练解决了多层人工神经元叠加产生的梯度消失问题。玻尔兹曼机（Boltzmann Machine）是一个全连接网络图，如果我们限制它的结构为二部图，那么就可以得到含有两层节点，仅在两层间建立相互连接的完全二部图，又称受限玻尔兹曼机（Restricted Boltzmann Machine, RBM）。这种边权的剪枝优化了运行速度，使得单层的RBM训练到收敛变得可能。

在RBM中，任意两个相连的神经元之间有一个权值$w$表示其连接强度，每个神经元自身有一个偏置系数$b$（对显层神经元$v$）和$c$（对隐层神经元$h$）来表示其自身权重。这样就可以用下面的函数来表示一个RBM的能量：

$$E(v,h) = -\sum_{i=1}^{N_v}b_iv_i-\sum_{j=1}^{N_h}c_jh_j - \sum_{i,j=1}^{N_v,N_h}W_{ij}v_ih_j$$

显层和隐层的的联合概率分布由能量函数来指定：

$$p(v,h) = \frac{1}{C}exp(-E(v,h))$$

其中$C$是被称为配分函数的归一化常数：

$$C = \sum_v\sum_hexp(-E(v,h))$$

在一个RBM中，隐层神经元$$h_j$$被激活的概率为：

$$p(h_j\mid v) = \sigma(b_j + \sum_iW_{ij}v_i)$$

由于是双向连接，显层神经元同样能被隐层神经元激活：

$$p(v_i\mid h) = \sigma(c_i + \sum_jW_{ij}h_j)$$

其中$\sigma$为Sigmoid函数，当然也可以设定为其他函数。值得注意的是，当中$\sigma$为线性函数时，DBN与PCA（主成分分析）是等价的。

同一层神经元之间具有独立性，所以概率密度亦满足独立性，故得到：

$$p(h\mid v) = \prod_{j=1}^{N_h}p(h_j\mid v)$$

$$p(v\mid h) = \prod_{i=1}^{N_v}p(v_i\mid h)$$

以上即为RBM的基本结构。DBN具有若干层的RBM，因此有一个显层，多个隐层。隐层神经元通常是二值的，显层神经元可以是二值或实数（以下我们只考虑二值的情况）。

它的工作原理如下：

当一条数据（如$x$）赋给显层后，RBM计算每个隐层神经元被激活的概率$$p(h_j\mid x), j=1,2,...,N_h$$，取一个$[0,1]$的随机数$\mu$作为阈值，大于该阈值的神经元被激活，否则不被激活，即：

$$h_j = \begin{cases}1 & p(h_j\mid x)\geq\mu \\
		0 & p(h_j\mid x) < \mu
\end{cases}$$

在给定隐层时，显层的计算方法是一样的。

了解工作原理之后，就可以看看RBM是如何通过数据学习的了：

RBM共有三个参数：$W,b,c$，也就是相应的权重和偏置需要学习。

对于一条样本数据$x$，采用对比散度（Constrastive Divergence, CD）算法对其进行训练如下：

(1) 将$x$赋给显层$$v_1$$，得到隐层中每个神经元被激活的概率$$p(h_1\mid v_1)$$；

(2) 从计算的概率分布中抽取一个样本$$h_1\sim p(h_1\mid v_1)$$；

(3) 用$$h_1$$重构显层，即通过隐层反推显层，计算显层中每个神经元被激活的概率$$p(v_2\mid h_1)$$；

(4) 同样地，从计算得到的概率分布中抽取一个样本$$v_2\sim p(v_2\mid h_1)$$；

(5) 通过$$v_2$$再次计算隐层中每个神经元被激活的概率，得到$$p(h_2\mid v_2)$$；

(6) 从计算的概率分布中抽取一个样本$$h_2\sim p(h_2\mid v_2)$$；

(7) 更新参数：

$$W\leftarrow W + \eta[p(h_1\mid v_1)v_1-p(h_2\mid v_2)v_2]$$

$$b\leftarrow b + \eta(v_1-v_2)$$

$$c\leftarrow c + \eta(h_1-h_2)$$

若干次训练后，隐层不仅能较为精准地显示显层的特征，同时还能够还原显层。当隐层神经元数量小于显层时，则会产生一种“数据压缩”的效果，也就类似于自动编码器。

在我们堆叠多层RBM后，传统的反向传播算法会由于高层的深度增加而产生梯度消失，导致优化低效，而DBN通过贪婪地每层进行充分的预训练，不但可以得到和全局优化等同的效果，同时还避免了高层的低效优化问题。

为了从DBN中生成样本，我们先从顶部最深的两个隐层上运行几个Gibbs采样步骤，得到由这两个隐层定义的RBM的一个样本，然后从该样本进行反向传播，最后得到显层生成出来的数据样本。

若想将DBN用于监督学习，可以将DBN改成ANN，即隐层的输出改为激活函数的直接输出，在最后一层加上softmax分类器，并将DBN训练得到的参数看作ANN的pre-train，即在此基础上通过BP算法进行判别性精调。

# 3、VAE

构建深度生成模型的目标基本是一致的——希望构建一个从简化后的隐变量$z$生成目标数据$X$的模型。更准确地讲，它们是假设$z$是服从某些常见分布的随机变量，然后希望训练一个模型$$X=g(z)$$，这个模型能够将原来的概率分布映射到训练集的概率分布，也就是说，他们的目的都是进行分布之间的变换。

# 4、GAN

假设我们得到了一批从构造的分布采样而来的数据$$\{\widehat{X}_1,\widehat{X}_2,...,\widehat{X}_n\}$$，还有一批从真实的分布采样而来的训练集数据$$\{X_1, X_2, ..., X_n\}$$，我们只有样本本身，没有分布表达式，没法用KL散度来度量分布之间的距离，GAN的思路是：既然没有合适的度量，干脆把这个距离度量也用神经网络训练出来吧。
