---
layout: post
title: "降维" 
---

# 1、引言

在大多数学习算法中，复杂度依赖于输入的维度$d$和数据样本的规模$N$。为了减少存储空间和计算时间，我们对降低输入的维度感兴趣。降低维度的主要方法有两种：特征选择和特征提取。

在特征选择（feature selection）中，我们感兴趣的是从$d$维中找出为我们提供最多信息的$k$个维，并且丢弃其他的$d-k$个维。

在特征提取（feature extraction）中，我们感兴趣的是将原来的$d$个维进行重新组合，得到新的$k$个维的集合。特征提取可以是监督的，也可以是无监督的，这取决于该方法是否使用输出信息。最广泛使用的特征提取方法是主成分分析（principal components analysis, PCA）和线性判别分析（linear discriminant analysis, LDA）。它们都是线性投影方法，分别是无监督和监督的。

# 2、特征选择








